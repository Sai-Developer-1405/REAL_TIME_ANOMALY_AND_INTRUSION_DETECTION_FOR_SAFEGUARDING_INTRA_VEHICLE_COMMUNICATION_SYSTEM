{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db415938-6830-466f-8d3a-98d4880f7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SwarmPackagePy in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (1.0.0a5)\n",
      "Requirement already satisfied: numpy in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from SwarmPackagePy) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from SwarmPackagePy) (3.9.2)\n",
      "Requirement already satisfied: pandas in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from SwarmPackagePy) (2.2.2)\n",
      "Requirement already satisfied: pytest in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from SwarmPackagePy) (7.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from matplotlib>=2.0.0->SwarmPackagePy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from pandas->SwarmPackagePy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from pandas->SwarmPackagePy) (2023.3)\n",
      "Requirement already satisfied: iniconfig in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from pytest->SwarmPackagePy) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from pytest->SwarmPackagePy) (1.0.0)\n",
      "Requirement already satisfied: colorama in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from pytest->SwarmPackagePy) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\sai_files\\sai_imp_files\\software_files\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->SwarmPackagePy) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SwarmPackagePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8dfa9c-a245-45ba-8d72-6253d331e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/etas/SynCAN/blob/master/train_2.zip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10138b1a-f92d-4479-a2b6-10b1e4cc031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SwarmPackagePy\n",
    "from SwarmPackagePy import testFunctions as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77eb9b4c-4878-49ed-86ae-49732a661d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_spider(spider, spiders):\n",
    "\n",
    "        spudis = list(spiders)\n",
    "\n",
    "        try:\n",
    "            pos = spudis.index(spider)\n",
    "            spudis.pop(pos)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        dists = np.array([np.linalg.norm(spider - s) for s in spudis])\n",
    "        m = dists.argmin()\n",
    "        d = dists[m]\n",
    "\n",
    "        return d, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee58223-4bd7-471f-85b5-9b0051af0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train = pd.read_csv('CAN.csv',nrows=14000)\n",
    "    train.fillna(0,inplace=True)\n",
    "    print(train)\n",
    "    print(train.shape)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train['ID'] = pd.Series(le.fit_transform(train['ID']))\n",
    "    print(train)\n",
    "\n",
    "    X = train.values[:, 1:7] \n",
    "    Y = train.values[:, 0]\n",
    "    print(Y)\n",
    "    #X = tf.easom_function(X[0].astype(int))\n",
    "    #print(X)\n",
    "    alh = SwarmPackagePy.ssa(10, tf.easom_function, -10, 6, 2, 20,0.4)\n",
    "    print(nearest_spider(0, X[0]))\n",
    "    print(nearest_spider(1, X[1]))\n",
    "    print(nearest_spider(2, X[2]))\n",
    "    print(nearest_spider(3, X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fd879f-ddc8-4480-b412-f55d01976de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Label         Time   ID  Signal1_of_ID  Signal2_of_ID  Signal3_of_ID  \\\n",
      "0          0  81008449.45  id3       0.200000       1.000000            0.0   \n",
      "1          0  81008456.75  id9       0.370003       0.000000            0.0   \n",
      "2          0  81008458.21  id7       0.044139       0.000000            0.0   \n",
      "3          0  81008459.28  id8       0.170534       0.000000            0.0   \n",
      "4          0  81008462.01  id5       0.173044       0.874886            0.0   \n",
      "...      ...          ...  ...            ...            ...            ...   \n",
      "13995      1  81033984.31  id5       0.174490       0.606627            0.0   \n",
      "13996      1  81033985.63  id5       0.174490       0.606627            0.0   \n",
      "13997      1  81033986.60  id5       0.174490       0.606627            0.0   \n",
      "13998      1  81033986.75  id9       0.295677       0.000000            0.0   \n",
      "13999      1  81033988.67  id5       0.174490       0.606627            0.0   \n",
      "\n",
      "       Signal4_of_ID  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "...              ...  \n",
      "13995            0.0  \n",
      "13996            0.0  \n",
      "13997            0.0  \n",
      "13998            0.0  \n",
      "13999            0.0  \n",
      "\n",
      "[14000 rows x 7 columns]\n",
      "(14000, 7)\n",
      "       Label         Time  ID  Signal1_of_ID  Signal2_of_ID  Signal3_of_ID  \\\n",
      "0          0  81008449.45   3       0.200000       1.000000            0.0   \n",
      "1          0  81008456.75   9       0.370003       0.000000            0.0   \n",
      "2          0  81008458.21   7       0.044139       0.000000            0.0   \n",
      "3          0  81008459.28   8       0.170534       0.000000            0.0   \n",
      "4          0  81008462.01   5       0.173044       0.874886            0.0   \n",
      "...      ...          ...  ..            ...            ...            ...   \n",
      "13995      1  81033984.31   5       0.174490       0.606627            0.0   \n",
      "13996      1  81033985.63   5       0.174490       0.606627            0.0   \n",
      "13997      1  81033986.60   5       0.174490       0.606627            0.0   \n",
      "13998      1  81033986.75   9       0.295677       0.000000            0.0   \n",
      "13999      1  81033988.67   5       0.174490       0.606627            0.0   \n",
      "\n",
      "       Signal4_of_ID  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "...              ...  \n",
      "13995            0.0  \n",
      "13996            0.0  \n",
      "13997            0.0  \n",
      "13998            0.0  \n",
      "13999            0.0  \n",
      "\n",
      "[14000 rows x 7 columns]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "(0.0, 4)\n",
      "(0.629997039, 2)\n",
      "(1.955861479, 2)\n",
      "(2.829466164, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "    estimator = svm.SVC(C=2.0,gamma='scale',kernel = 'rbf', random_state = 0)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    hr = accuracy_score(y_test,y_pred)*100\n",
    "    mr = precision_score(y_test, y_pred,average='macro') * 100\n",
    "    fr = recall_score(y_test, y_pred,average='macro') * 100\n",
    "    cr = f1_score(y_test, y_pred,average='macro') * 100\n",
    "    print(str(hr)+\" \"+str(mr)+\" \"+str(fr)+\" \"+str(cr))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(str(fp)+\" \"+str(fn))\n",
    "\n",
    "    X = train.values[:, 3:7] \n",
    "    Y = train.values[:, 0]\n",
    "    print(Y)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    estimator = KNeighborsClassifier()\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    hr = accuracy_score(y_test,y_pred)*100\n",
    "    mr = precision_score(y_test, y_pred,average='macro') * 100\n",
    "    fr = recall_score(y_test, y_pred,average='macro') * 100\n",
    "    cr = f1_score(y_test, y_pred,average='macro') * 100\n",
    "    print(str(hr)+\" \"+str(mr)+\" \"+str(fr)+\" \"+str(cr))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(str(fp)+\" \"+str(fn))\n",
    "\n",
    "    X = train.values[:, 4:7] \n",
    "    Y = train.values[:, 0]\n",
    "    print(Y)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "    estimator = DecisionTreeClassifier(max_features=2)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    hr = accuracy_score(y_test,y_pred)*100\n",
    "    mr = precision_score(y_test, y_pred,average='macro') * 100\n",
    "    fr = recall_score(y_test, y_pred,average='macro') * 100\n",
    "    cr = f1_score(y_test, y_pred,average='macro') * 100\n",
    "    print(str(hr)+\" \"+str(mr)+\" \"+str(fr)+\" \"+str(cr))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(str(fp)+\" \"+str(fn))\n",
    "    X = train.values[:, 1:7] \n",
    "    Y = train.values[:, 0]\n",
    "    print(Y)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    estimator = svm.SVC(C=2.0,gamma='scale',kernel = 'rbf', random_state = 0)\n",
    "    selector = GeneticSelectionCV(estimator,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=5,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=5,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=2,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    y_pred = selector.predict(X_test)\n",
    "    hr = accuracy_score(y_pred,y_pred)*100\n",
    "    mr = precision_score(y_pred, y_pred,average='macro') * 100\n",
    "    fr = recall_score(y_pred, y_pred,average='macro') * 100\n",
    "    cr = f1_score(y_pred, y_pred,average='macro') * 100\n",
    "    print(str(hr)+\" \"+str(mr)+\" \"+str(fr)+\" \"+str(cr))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_pred).ravel()\n",
    "    print(str(fp)+\" \"+str(fn))\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e6bbc-0e21-495e-b9e6-e6438ce9581d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
